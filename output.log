nohup: ignoring input
Namespace(AdamW=True, base_lr=0.005, batch_size=12, ckpt='checkpoints/sam_vit_b_01ec64.pth', dataset='BraTS', deterministic=1, dice_param=0.8, exp='BraTS_240', img_size=240, is_pretrain=True, list_dir='./lists/lists_BraTS20', lora_ckpt=None, max_epochs=3, max_iterations=30000, module='sam_lora_image_encoder', n_gpu=2, num_classes=8, output='./BraTS_output', rank=4, root_path='./trainset', seed=1234, stop_epoch=160, vit_name='vit_b', warmup=True, warmup_period=250)
The length of train set is: 2790
117 iterations per epoch. 351 max iterations 
  0%|                                           | 0/3 [00:00<?, ?it/s]iteration 1 : loss : 2.040632, loss_ce: 6.250729, loss_dice: 0.988108
iteration 2 : loss : 1.521453, loss_ce: 3.696704, loss_dice: 0.977640
iteration 3 : loss : 1.340254, loss_ce: 2.803710, loss_dice: 0.974389
iteration 4 : loss : 1.166013, loss_ce: 2.030555, loss_dice: 0.949878
iteration 5 : loss : 1.084567, loss_ce: 1.674477, loss_dice: 0.937090
iteration 6 : loss : 0.995984, loss_ce: 1.276922, loss_dice: 0.925749
iteration 7 : loss : 0.917927, loss_ce: 0.948510, loss_dice: 0.910281
iteration 8 : loss : 0.827153, loss_ce: 0.570266, loss_dice: 0.891374
iteration 9 : loss : 0.768812, loss_ce: 0.305038, loss_dice: 0.884756
iteration 10 : loss : 0.735968, loss_ce: 0.140593, loss_dice: 0.884812
iteration 11 : loss : 0.730840, loss_ce: 0.104354, loss_dice: 0.887462
iteration 12 : loss : 0.736297, loss_ce: 0.125801, loss_dice: 0.888921
iteration 13 : loss : 0.740474, loss_ce: 0.144391, loss_dice: 0.889495
iteration 14 : loss : 0.732791, loss_ce: 0.107253, loss_dice: 0.889176
iteration 15 : loss : 0.751383, loss_ce: 0.199218, loss_dice: 0.889424
iteration 16 : loss : 0.735711, loss_ce: 0.130144, loss_dice: 0.887102
iteration 17 : loss : 0.718003, loss_ce: 0.094443, loss_dice: 0.873893
iteration 18 : loss : 0.665578, loss_ce: 0.180905, loss_dice: 0.786746
iteration 19 : loss : 0.590107, loss_ce: 0.206428, loss_dice: 0.686026
iteration 20 : loss : 0.297276, loss_ce: 0.150749, loss_dice: 0.333908
iteration 21 : loss : 0.309990, loss_ce: 0.214169, loss_dice: 0.333946
iteration 22 : loss : 0.358427, loss_ce: 0.454200, loss_dice: 0.334484
iteration 23 : loss : 0.308304, loss_ce: 0.206089, loss_dice: 0.333858
iteration 24 : loss : 0.317107, loss_ce: 0.249399, loss_dice: 0.334033
iteration 25 : loss : 0.326632, loss_ce: 0.296408, loss_dice: 0.334188
iteration 26 : loss : 0.296598, loss_ce: 0.147728, loss_dice: 0.333816
iteration 27 : loss : 0.306212, loss_ce: 0.192578, loss_dice: 0.334621
iteration 28 : loss : 0.317412, loss_ce: 0.230847, loss_dice: 0.339053
iteration 29 : loss : 0.304438, loss_ce: 0.183718, loss_dice: 0.334618
iteration 30 : loss : 0.290701, loss_ce: 0.129022, loss_dice: 0.331121
iteration 31 : loss : 0.292086, loss_ce: 0.155465, loss_dice: 0.326241
iteration 32 : loss : 0.286940, loss_ce: 0.118814, loss_dice: 0.328972
iteration 33 : loss : 0.280905, loss_ce: 0.096067, loss_dice: 0.327114
iteration 34 : loss : 0.273490, loss_ce: 0.063398, loss_dice: 0.326013
iteration 35 : loss : 0.268089, loss_ce: 0.063060, loss_dice: 0.319346
iteration 36 : loss : 0.273922, loss_ce: 0.106629, loss_dice: 0.315745
iteration 37 : loss : 0.268021, loss_ce: 0.071376, loss_dice: 0.317182
iteration 38 : loss : 0.270714, loss_ce: 0.080484, loss_dice: 0.318272
iteration 39 : loss : 0.277972, loss_ce: 0.148349, loss_dice: 0.310378
iteration 40 : loss : 0.271672, loss_ce: 0.097947, loss_dice: 0.315103
iteration 41 : loss : 0.280405, loss_ce: 0.125807, loss_dice: 0.319055
iteration 42 : loss : 0.256688, loss_ce: 0.056975, loss_dice: 0.306616
iteration 43 : loss : 0.268686, loss_ce: 0.080624, loss_dice: 0.315701
iteration 44 : loss : 0.265471, loss_ce: 0.057864, loss_dice: 0.317373
iteration 45 : loss : 0.264404, loss_ce: 0.035331, loss_dice: 0.321672
iteration 46 : loss : 0.260732, loss_ce: 0.077877, loss_dice: 0.306446
iteration 47 : loss : 0.300794, loss_ce: 0.278455, loss_dice: 0.306378
iteration 48 : loss : 0.261051, loss_ce: 0.036110, loss_dice: 0.317286
iteration 49 : loss : 0.278313, loss_ce: 0.086946, loss_dice: 0.326155
iteration 50 : loss : 0.259377, loss_ce: 0.035265, loss_dice: 0.315404
iteration 51 : loss : 0.307955, loss_ce: 0.206811, loss_dice: 0.333241
iteration 52 : loss : 0.290002, loss_ce: 0.123999, loss_dice: 0.331502
iteration 53 : loss : 0.293854, loss_ce: 0.133372, loss_dice: 0.333975
iteration 54 : loss : 0.287097, loss_ce: 0.100391, loss_dice: 0.333773
iteration 55 : loss : 0.296626, loss_ce: 0.147320, loss_dice: 0.333952
iteration 56 : loss : 0.309672, loss_ce: 0.211656, loss_dice: 0.334176
iteration 57 : loss : 0.297585, loss_ce: 0.152005, loss_dice: 0.333980
iteration 58 : loss : 0.278542, loss_ce: 0.058381, loss_dice: 0.333583
iteration 59 : loss : 0.280647, loss_ce: 0.068650, loss_dice: 0.333646
iteration 60 : loss : 0.288424, loss_ce: 0.106739, loss_dice: 0.333845
iteration 61 : loss : 0.283518, loss_ce: 0.082744, loss_dice: 0.333711
iteration 62 : loss : 0.281150, loss_ce: 0.071212, loss_dice: 0.333635
iteration 63 : loss : 0.281473, loss_ce: 0.061313, loss_dice: 0.336513
iteration 64 : loss : 0.277644, loss_ce: 0.059372, loss_dice: 0.332212
iteration 65 : loss : 0.275862, loss_ce: 0.061543, loss_dice: 0.329441
iteration 66 : loss : 0.267347, loss_ce: 0.057539, loss_dice: 0.319799
iteration 67 : loss : 0.261262, loss_ce: 0.082570, loss_dice: 0.305934
iteration 68 : loss : 0.276533, loss_ce: 0.138415, loss_dice: 0.311062
iteration 69 : loss : 0.263486, loss_ce: 0.114528, loss_dice: 0.300725
iteration 70 : loss : 0.271198, loss_ce: 0.083311, loss_dice: 0.318170
iteration 71 : loss : 0.266016, loss_ce: 0.044607, loss_dice: 0.321368
iteration 72 : loss : 0.266300, loss_ce: 0.064919, loss_dice: 0.316646
iteration 73 : loss : 0.255427, loss_ce: 0.057216, loss_dice: 0.304980
iteration 74 : loss : 0.249413, loss_ce: 0.080818, loss_dice: 0.291562
iteration 75 : loss : 0.263565, loss_ce: 0.126919, loss_dice: 0.297726
iteration 76 : loss : 0.251936, loss_ce: 0.104195, loss_dice: 0.288871
iteration 77 : loss : 0.250741, loss_ce: 0.077798, loss_dice: 0.293977
iteration 78 : loss : 0.254816, loss_ce: 0.064264, loss_dice: 0.302454
iteration 79 : loss : 0.254595, loss_ce: 0.067318, loss_dice: 0.301415
iteration 80 : loss : 0.256105, loss_ce: 0.072218, loss_dice: 0.302077
iteration 81 : loss : 0.254061, loss_ce: 0.066400, loss_dice: 0.300976
iteration 82 : loss : 0.242718, loss_ce: 0.068879, loss_dice: 0.286178
iteration 83 : loss : 0.249729, loss_ce: 0.070726, loss_dice: 0.294479
iteration 84 : loss : 0.241799, loss_ce: 0.074485, loss_dice: 0.283628
iteration 85 : loss : 0.244026, loss_ce: 0.085339, loss_dice: 0.283697
iteration 86 : loss : 0.240595, loss_ce: 0.060311, loss_dice: 0.285666
iteration 87 : loss : 0.238762, loss_ce: 0.094458, loss_dice: 0.274838
iteration 88 : loss : 0.238473, loss_ce: 0.051004, loss_dice: 0.285340
iteration 89 : loss : 0.235571, loss_ce: 0.055892, loss_dice: 0.280491
iteration 90 : loss : 0.239288, loss_ce: 0.091248, loss_dice: 0.276298
iteration 91 : loss : 0.228271, loss_ce: 0.097340, loss_dice: 0.261003
iteration 92 : loss : 0.231074, loss_ce: 0.073483, loss_dice: 0.270471
iteration 93 : loss : 0.249604, loss_ce: 0.072033, loss_dice: 0.293997
iteration 94 : loss : 0.233427, loss_ce: 0.131411, loss_dice: 0.258931
iteration 95 : loss : 0.225634, loss_ce: 0.032533, loss_dice: 0.273909
iteration 96 : loss : 0.237644, loss_ce: 0.096008, loss_dice: 0.273052
iteration 97 : loss : 0.241274, loss_ce: 0.081598, loss_dice: 0.281193
iteration 98 : loss : 0.254508, loss_ce: 0.077763, loss_dice: 0.298695
iteration 99 : loss : 0.244743, loss_ce: 0.103019, loss_dice: 0.280174
iteration 100 : loss : 0.224686, loss_ce: 0.079313, loss_dice: 0.261029
NaN or Inf found in input tensor.
iteration 101 : loss : 0.245954, loss_ce: 0.070390, loss_dice: 0.289845
iteration 102 : loss : 0.225868, loss_ce: 0.079056, loss_dice: 0.262571
iteration 103 : loss : 0.242185, loss_ce: 0.111732, loss_dice: 0.274798
iteration 104 : loss : 0.241926, loss_ce: 0.042782, loss_dice: 0.291712
iteration 105 : loss : 0.232394, loss_ce: 0.060280, loss_dice: 0.275423
iteration 106 : loss : 0.245633, loss_ce: 0.102663, loss_dice: 0.281375
iteration 107 : loss : 0.239429, loss_ce: 0.103311, loss_dice: 0.273459
iteration 108 : loss : 0.223867, loss_ce: 0.082913, loss_dice: 0.259105
iteration 109 : loss : 0.232733, loss_ce: 0.068657, loss_dice: 0.273752
iteration 110 : loss : 0.230621, loss_ce: 0.076339, loss_dice: 0.269192
iteration 111 : loss : 0.250300, loss_ce: 0.142251, loss_dice: 0.277312
iteration 112 : loss : 0.238022, loss_ce: 0.079659, loss_dice: 0.277612
iteration 113 : loss : 0.232120, loss_ce: 0.039028, loss_dice: 0.280393
iteration 114 : loss : 0.235318, loss_ce: 0.048070, loss_dice: 0.282130
iteration 115 : loss : 0.244144, loss_ce: 0.102737, loss_dice: 0.279496
iteration 116 : loss : 0.233438, loss_ce: 0.088463, loss_dice: 0.269682
iteration 117 : loss : 0.239566, loss_ce: 0.104706, loss_dice: 0.273281
 33%|███████████▋                       | 1/3 [00:38<01:17, 38.58s/it]iteration 118 : loss : 0.236677, loss_ce: 0.050245, loss_dice: 0.283286
iteration 119 : loss : 0.230030, loss_ce: 0.055678, loss_dice: 0.273618
iteration 120 : loss : 0.247492, loss_ce: 0.099482, loss_dice: 0.284494
iteration 121 : loss : 0.227240, loss_ce: 0.111695, loss_dice: 0.256127
iteration 122 : loss : 0.236686, loss_ce: 0.037430, loss_dice: 0.286500
iteration 123 : loss : 0.234521, loss_ce: 0.036709, loss_dice: 0.283974
iteration 124 : loss : 0.241899, loss_ce: 0.074835, loss_dice: 0.283665
iteration 125 : loss : 0.228966, loss_ce: 0.096564, loss_dice: 0.262067
iteration 126 : loss : 0.235016, loss_ce: 0.142930, loss_dice: 0.258038
iteration 127 : loss : 0.224767, loss_ce: 0.099401, loss_dice: 0.256108
iteration 128 : loss : 0.226333, loss_ce: 0.058774, loss_dice: 0.268222
iteration 129 : loss : 0.215107, loss_ce: 0.040719, loss_dice: 0.258704
iteration 130 : loss : 0.233737, loss_ce: 0.072622, loss_dice: 0.274015
iteration 131 : loss : 0.231797, loss_ce: 0.071741, loss_dice: 0.271811
iteration 132 : loss : 0.258699, loss_ce: 0.129108, loss_dice: 0.291097
iteration 133 : loss : 0.250423, loss_ce: 0.112659, loss_dice: 0.284864
iteration 134 : loss : 0.229597, loss_ce: 0.080151, loss_dice: 0.266958
iteration 135 : loss : 0.214912, loss_ce: 0.058786, loss_dice: 0.253943
iteration 136 : loss : 0.218218, loss_ce: 0.050129, loss_dice: 0.260240
iteration 137 : loss : 0.213965, loss_ce: 0.074374, loss_dice: 0.248863
iteration 138 : loss : 0.233601, loss_ce: 0.138800, loss_dice: 0.257302
iteration 139 : loss : 0.209271, loss_ce: 0.121116, loss_dice: 0.231309
iteration 140 : loss : 0.247382, loss_ce: 0.035754, loss_dice: 0.300289
iteration 141 : loss : 0.221995, loss_ce: 0.061654, loss_dice: 0.262080
iteration 142 : loss : 0.231028, loss_ce: 0.073949, loss_dice: 0.270297
iteration 143 : loss : 0.224635, loss_ce: 0.095666, loss_dice: 0.256877
iteration 144 : loss : 0.237021, loss_ce: 0.056952, loss_dice: 0.282039
iteration 145 : loss : 0.211745, loss_ce: 0.053205, loss_dice: 0.251380
iteration 146 : loss : 0.201748, loss_ce: 0.065948, loss_dice: 0.235698
iteration 147 : loss : 0.218219, loss_ce: 0.070565, loss_dice: 0.255133
iteration 148 : loss : 0.210379, loss_ce: 0.038168, loss_dice: 0.253431
iteration 149 : loss : 0.223510, loss_ce: 0.073185, loss_dice: 0.261091
iteration 150 : loss : 0.174139, loss_ce: 0.028443, loss_dice: 0.210564
iteration 151 : loss : 0.208299, loss_ce: 0.025276, loss_dice: 0.254055
iteration 152 : loss : 0.208776, loss_ce: 0.043287, loss_dice: 0.250148
iteration 153 : loss : 0.230746, loss_ce: 0.066275, loss_dice: 0.271863
iteration 154 : loss : 0.200111, loss_ce: 0.081081, loss_dice: 0.229868
iteration 155 : loss : 0.211580, loss_ce: 0.047436, loss_dice: 0.252616
iteration 156 : loss : 0.198470, loss_ce: 0.066012, loss_dice: 0.231585
iteration 157 : loss : 0.200663, loss_ce: 0.053483, loss_dice: 0.237457
iteration 158 : loss : 0.244786, loss_ce: 0.068221, loss_dice: 0.288927
iteration 159 : loss : 0.215953, loss_ce: 0.041103, loss_dice: 0.259665
iteration 160 : loss : 0.246397, loss_ce: 0.103087, loss_dice: 0.282225
iteration 161 : loss : 0.229173, loss_ce: 0.130621, loss_dice: 0.253811
iteration 162 : loss : 0.264642, loss_ce: 0.100851, loss_dice: 0.305590
iteration 163 : loss : 0.244709, loss_ce: 0.057842, loss_dice: 0.291426
iteration 164 : loss : 0.359781, loss_ce: 0.104735, loss_dice: 0.423543
iteration 165 : loss : 0.328242, loss_ce: 0.037910, loss_dice: 0.400825
iteration 166 : loss : 0.263628, loss_ce: 0.079154, loss_dice: 0.309746
iteration 167 : loss : 0.266653, loss_ce: 0.141735, loss_dice: 0.297882
iteration 168 : loss : 0.243298, loss_ce: 0.048913, loss_dice: 0.291894
iteration 169 : loss : 0.236483, loss_ce: 0.089314, loss_dice: 0.273275
iteration 170 : loss : 0.231311, loss_ce: 0.139346, loss_dice: 0.254303
iteration 171 : loss : 0.253509, loss_ce: 0.073910, loss_dice: 0.298409
iteration 172 : loss : 0.276242, loss_ce: 0.204783, loss_dice: 0.294107
iteration 173 : loss : 0.195896, loss_ce: 0.033254, loss_dice: 0.236556
iteration 174 : loss : 0.250444, loss_ce: 0.068806, loss_dice: 0.295853
iteration 175 : loss : 0.286360, loss_ce: 0.259681, loss_dice: 0.293030
iteration 176 : loss : 0.263949, loss_ce: 0.097457, loss_dice: 0.305572
iteration 177 : loss : 0.279088, loss_ce: 0.083053, loss_dice: 0.328097
iteration 178 : loss : 0.312384, loss_ce: 0.225136, loss_dice: 0.334196
iteration 179 : loss : 0.313267, loss_ce: 0.229750, loss_dice: 0.334147
iteration 180 : loss : 0.288765, loss_ce: 0.109163, loss_dice: 0.333666
iteration 181 : loss : 0.278919, loss_ce: 0.072524, loss_dice: 0.330517
iteration 182 : loss : 0.289846, loss_ce: 0.128753, loss_dice: 0.330119
iteration 183 : loss : 0.292506, loss_ce: 0.128104, loss_dice: 0.333607
iteration 184 : loss : 0.313923, loss_ce: 0.225340, loss_dice: 0.336069
iteration 185 : loss : 0.292122, loss_ce: 0.125830, loss_dice: 0.333696
iteration 186 : loss : 0.347169, loss_ce: 0.398851, loss_dice: 0.334248
iteration 187 : loss : 0.345967, loss_ce: 0.393067, loss_dice: 0.334192
iteration 188 : loss : 0.333953, loss_ce: 0.333171, loss_dice: 0.334148
iteration 189 : loss : 0.301688, loss_ce: 0.173313, loss_dice: 0.333782
iteration 190 : loss : 0.310425, loss_ce: 0.222884, loss_dice: 0.332310
iteration 191 : loss : 0.310195, loss_ce: 0.221540, loss_dice: 0.332359
iteration 192 : loss : 0.295443, loss_ce: 0.158518, loss_dice: 0.329674
iteration 193 : loss : 0.287387, loss_ce: 0.121631, loss_dice: 0.328826
iteration 194 : loss : 0.297810, loss_ce: 0.175783, loss_dice: 0.328317
iteration 195 : loss : 0.283690, loss_ce: 0.111657, loss_dice: 0.326699
iteration 196 : loss : 0.286294, loss_ce: 0.123390, loss_dice: 0.327020
iteration 197 : loss : 0.291727, loss_ce: 0.150852, loss_dice: 0.326946
iteration 198 : loss : 0.280944, loss_ce: 0.099162, loss_dice: 0.326389
iteration 199 : loss : 0.280818, loss_ce: 0.100538, loss_dice: 0.325888
iteration 200 : loss : 0.279594, loss_ce: 0.095801, loss_dice: 0.325542
NaN or Inf found in input tensor.
iteration 201 : loss : 0.285005, loss_ce: 0.109216, loss_dice: 0.328952
iteration 202 : loss : 0.281336, loss_ce: 0.089417, loss_dice: 0.329316
iteration 203 : loss : 0.281896, loss_ce: 0.098900, loss_dice: 0.327646
iteration 204 : loss : 0.278319, loss_ce: 0.088297, loss_dice: 0.325825
iteration 205 : loss : 0.284564, loss_ce: 0.093722, loss_dice: 0.332274
iteration 206 : loss : 0.284958, loss_ce: 0.092593, loss_dice: 0.333049
iteration 207 : loss : 0.292739, loss_ce: 0.129700, loss_dice: 0.333499
iteration 208 : loss : 0.297214, loss_ce: 0.151683, loss_dice: 0.333597
iteration 209 : loss : 0.282003, loss_ce: 0.078695, loss_dice: 0.332830
iteration 210 : loss : 0.290750, loss_ce: 0.124395, loss_dice: 0.332339
iteration 211 : loss : 0.284442, loss_ce: 0.101205, loss_dice: 0.330251
iteration 212 : loss : 0.287226, loss_ce: 0.131208, loss_dice: 0.326230
iteration 213 : loss : 0.284485, loss_ce: 0.127791, loss_dice: 0.323659
iteration 214 : loss : 0.281449, loss_ce: 0.115389, loss_dice: 0.322964
iteration 215 : loss : 0.278402, loss_ce: 0.092997, loss_dice: 0.324753
iteration 216 : loss : 0.274547, loss_ce: 0.065115, loss_dice: 0.326905
iteration 217 : loss : 0.279943, loss_ce: 0.084758, loss_dice: 0.328740
iteration 218 : loss : 0.286346, loss_ce: 0.111957, loss_dice: 0.329944
iteration 219 : loss : 0.284523, loss_ce: 0.104555, loss_dice: 0.329515
iteration 220 : loss : 0.277187, loss_ce: 0.074694, loss_dice: 0.327810
NaN or Inf found in input tensor.
iteration 221 : loss : 0.279167, loss_ce: 0.090839, loss_dice: 0.326249
iteration 222 : loss : 0.277621, loss_ce: 0.086537, loss_dice: 0.325392
iteration 223 : loss : 0.280100, loss_ce: 0.098324, loss_dice: 0.325544
iteration 224 : loss : 0.278579, loss_ce: 0.087334, loss_dice: 0.326391
iteration 225 : loss : 0.281243, loss_ce: 0.096405, loss_dice: 0.327453
iteration 226 : loss : 0.278361, loss_ce: 0.081182, loss_dice: 0.327655
iteration 227 : loss : 0.275281, loss_ce: 0.066000, loss_dice: 0.327601
iteration 228 : loss : 0.277855, loss_ce: 0.078830, loss_dice: 0.327612
iteration 229 : loss : 0.279487, loss_ce: 0.087323, loss_dice: 0.327528
iteration 230 : loss : 0.275860, loss_ce: 0.070873, loss_dice: 0.327107
iteration 231 : loss : 0.278573, loss_ce: 0.084246, loss_dice: 0.327155
iteration 232 : loss : 0.272829, loss_ce: 0.056250, loss_dice: 0.326973
iteration 233 : loss : 0.278048, loss_ce: 0.080935, loss_dice: 0.327326
iteration 234 : loss : 0.271807, loss_ce: 0.033629, loss_dice: 0.331351
 67%|███████████████████████▎           | 2/3 [01:08<00:33, 33.57s/it]iteration 235 : loss : 0.273771, loss_ce: 0.050860, loss_dice: 0.329499
iteration 236 : loss : 0.283434, loss_ce: 0.092548, loss_dice: 0.331155
iteration 237 : loss : 0.281775, loss_ce: 0.083512, loss_dice: 0.331341
iteration 238 : loss : 0.286360, loss_ce: 0.106673, loss_dice: 0.331282
iteration 239 : loss : 0.277455, loss_ce: 0.069114, loss_dice: 0.329541
iteration 240 : loss : 0.281986, loss_ce: 0.101785, loss_dice: 0.327036
NaN or Inf found in input tensor.
iteration 241 : loss : 0.282685, loss_ce: 0.116622, loss_dice: 0.324201
iteration 242 : loss : 0.278702, loss_ce: 0.085404, loss_dice: 0.327026
iteration 243 : loss : 0.278078, loss_ce: 0.076475, loss_dice: 0.328479
iteration 244 : loss : 0.277905, loss_ce: 0.073656, loss_dice: 0.328967
iteration 245 : loss : 0.286719, loss_ce: 0.116411, loss_dice: 0.329296
iteration 246 : loss : 0.285678, loss_ce: 0.116176, loss_dice: 0.328054
iteration 247 : loss : 0.277379, loss_ce: 0.089617, loss_dice: 0.324319
iteration 248 : loss : 0.277563, loss_ce: 0.083932, loss_dice: 0.325971
iteration 249 : loss : 0.289785, loss_ce: 0.141297, loss_dice: 0.326907
iteration 250 : loss : 0.280116, loss_ce: 0.097812, loss_dice: 0.325692
iteration 251 : loss : 0.274179, loss_ce: 0.067809, loss_dice: 0.325771
iteration 252 : loss : 0.284949, loss_ce: 0.120278, loss_dice: 0.326117
iteration 253 : loss : 0.273791, loss_ce: 0.062801, loss_dice: 0.326539
iteration 254 : loss : 0.280046, loss_ce: 0.090216, loss_dice: 0.327504
iteration 255 : loss : 0.285495, loss_ce: 0.114018, loss_dice: 0.328364
iteration 256 : loss : 0.281676, loss_ce: 0.097184, loss_dice: 0.327799
iteration 257 : loss : 0.286159, loss_ce: 0.122810, loss_dice: 0.326996
iteration 258 : loss : 0.283852, loss_ce: 0.119583, loss_dice: 0.324920
iteration 259 : loss : 0.277857, loss_ce: 0.095799, loss_dice: 0.323371
iteration 260 : loss : 0.281082, loss_ce: 0.114579, loss_dice: 0.322708
iteration 261 : loss : 0.276974, loss_ce: 0.089738, loss_dice: 0.323782
iteration 262 : loss : 0.280099, loss_ce: 0.098256, loss_dice: 0.325559
iteration 263 : loss : 0.279580, loss_ce: 0.090354, loss_dice: 0.326887
iteration 264 : loss : 0.287225, loss_ce: 0.124131, loss_dice: 0.327999
iteration 265 : loss : 0.278488, loss_ce: 0.082058, loss_dice: 0.327595
iteration 266 : loss : 0.275347, loss_ce: 0.067358, loss_dice: 0.327345
iteration 267 : loss : 0.279109, loss_ce: 0.087215, loss_dice: 0.327082
iteration 268 : loss : 0.275407, loss_ce: 0.070842, loss_dice: 0.326548
iteration 269 : loss : 0.274719, loss_ce: 0.068307, loss_dice: 0.326322
iteration 270 : loss : 0.278660, loss_ce: 0.086785, loss_dice: 0.326629
iteration 271 : loss : 0.276614, loss_ce: 0.075734, loss_dice: 0.326834
iteration 272 : loss : 0.278723, loss_ce: 0.084480, loss_dice: 0.327283
iteration 273 : loss : 0.277237, loss_ce: 0.076158, loss_dice: 0.327506
iteration 274 : loss : 0.280175, loss_ce: 0.090545, loss_dice: 0.327583
iteration 275 : loss : 0.282572, loss_ce: 0.104008, loss_dice: 0.327213
iteration 276 : loss : 0.282363, loss_ce: 0.107095, loss_dice: 0.326180
iteration 277 : loss : 0.274026, loss_ce: 0.070793, loss_dice: 0.324835
iteration 278 : loss : 0.277258, loss_ce: 0.088645, loss_dice: 0.324411
iteration 279 : loss : 0.280470, loss_ce: 0.103387, loss_dice: 0.324740
iteration 280 : loss : 0.274814, loss_ce: 0.072302, loss_dice: 0.325442
NaN or Inf found in input tensor.
iteration 281 : loss : 0.275375, loss_ce: 0.072275, loss_dice: 0.326150
iteration 282 : loss : 0.279263, loss_ce: 0.086553, loss_dice: 0.327440
iteration 283 : loss : 0.278258, loss_ce: 0.079370, loss_dice: 0.327980
iteration 284 : loss : 0.278810, loss_ce: 0.081060, loss_dice: 0.328247
iteration 285 : loss : 0.279020, loss_ce: 0.082909, loss_dice: 0.328047
iteration 286 : loss : 0.281046, loss_ce: 0.094518, loss_dice: 0.327678
iteration 287 : loss : 0.277171, loss_ce: 0.079765, loss_dice: 0.326522
iteration 288 : loss : 0.276810, loss_ce: 0.081437, loss_dice: 0.325654
iteration 289 : loss : 0.279126, loss_ce: 0.095789, loss_dice: 0.324960
iteration 290 : loss : 0.278221, loss_ce: 0.092196, loss_dice: 0.324727
iteration 291 : loss : 0.277159, loss_ce: 0.088121, loss_dice: 0.324419
iteration 292 : loss : 0.275185, loss_ce: 0.075718, loss_dice: 0.325052
iteration 293 : loss : 0.277828, loss_ce: 0.084586, loss_dice: 0.326139
iteration 294 : loss : 0.280153, loss_ce: 0.092780, loss_dice: 0.326997
iteration 295 : loss : 0.281178, loss_ce: 0.096091, loss_dice: 0.327449
iteration 296 : loss : 0.280067, loss_ce: 0.091100, loss_dice: 0.327309
iteration 297 : loss : 0.275055, loss_ce: 0.068668, loss_dice: 0.326652
iteration 298 : loss : 0.276380, loss_ce: 0.076763, loss_dice: 0.326284
iteration 299 : loss : 0.280122, loss_ce: 0.096097, loss_dice: 0.326129
iteration 300 : loss : 0.276107, loss_ce: 0.078605, loss_dice: 0.325482
iteration 301 : loss : 0.279715, loss_ce: 0.097552, loss_dice: 0.325255
iteration 302 : loss : 0.285605, loss_ce: 0.127359, loss_dice: 0.325166
iteration 303 : loss : 0.273350, loss_ce: 0.065982, loss_dice: 0.325191
iteration 304 : loss : 0.276438, loss_ce: 0.081537, loss_dice: 0.325163
iteration 305 : loss : 0.275125, loss_ce: 0.070052, loss_dice: 0.326393
iteration 306 : loss : 0.274497, loss_ce: 0.062323, loss_dice: 0.327541
iteration 307 : loss : 0.275843, loss_ce: 0.065522, loss_dice: 0.328423
iteration 308 : loss : 0.284619, loss_ce: 0.105514, loss_dice: 0.329395
iteration 309 : loss : 0.276201, loss_ce: 0.065738, loss_dice: 0.328817
iteration 310 : loss : 0.277969, loss_ce: 0.076172, loss_dice: 0.328419
iteration 311 : loss : 0.284343, loss_ce: 0.109806, loss_dice: 0.327977
iteration 312 : loss : 0.283973, loss_ce: 0.114544, loss_dice: 0.326330
iteration 313 : loss : 0.279288, loss_ce: 0.101083, loss_dice: 0.323839
iteration 314 : loss : 0.278475, loss_ce: 0.104564, loss_dice: 0.321953
iteration 315 : loss : 0.277469, loss_ce: 0.099297, loss_dice: 0.322012
iteration 316 : loss : 0.276567, loss_ce: 0.080356, loss_dice: 0.325619
iteration 317 : loss : 0.283486, loss_ce: 0.110561, loss_dice: 0.326718
iteration 318 : loss : 0.288173, loss_ce: 0.126330, loss_dice: 0.328633
iteration 319 : loss : 0.279176, loss_ce: 0.081075, loss_dice: 0.328702
iteration 320 : loss : 0.279254, loss_ce: 0.081101, loss_dice: 0.328793
NaN or Inf found in input tensor.
iteration 321 : loss : 0.280875, loss_ce: 0.090357, loss_dice: 0.328505
iteration 322 : loss : 0.280755, loss_ce: 0.092954, loss_dice: 0.327706
iteration 323 : loss : 0.281940, loss_ce: 0.103768, loss_dice: 0.326483
iteration 324 : loss : 0.279716, loss_ce: 0.099694, loss_dice: 0.324722
iteration 325 : loss : 0.276354, loss_ce: 0.088221, loss_dice: 0.323387
iteration 326 : loss : 0.279529, loss_ce: 0.106824, loss_dice: 0.322705
iteration 327 : loss : 0.273703, loss_ce: 0.069106, loss_dice: 0.324852
iteration 328 : loss : 0.279302, loss_ce: 0.094648, loss_dice: 0.325466
iteration 329 : loss : 0.283097, loss_ce: 0.105811, loss_dice: 0.327419
iteration 330 : loss : 0.277324, loss_ce: 0.074303, loss_dice: 0.328079
iteration 331 : loss : 0.274043, loss_ce: 0.056255, loss_dice: 0.328490
iteration 332 : loss : 0.284059, loss_ce: 0.103455, loss_dice: 0.329210
iteration 333 : loss : 0.281221, loss_ce: 0.090887, loss_dice: 0.328804
iteration 334 : loss : 0.283030, loss_ce: 0.102617, loss_dice: 0.328133
iteration 335 : loss : 0.280132, loss_ce: 0.094192, loss_dice: 0.326617
iteration 336 : loss : 0.277245, loss_ce: 0.087023, loss_dice: 0.324801
iteration 337 : loss : 0.274193, loss_ce: 0.070193, loss_dice: 0.325192
iteration 338 : loss : 0.281025, loss_ce: 0.109258, loss_dice: 0.323967
iteration 339 : loss : 0.279855, loss_ce: 0.101216, loss_dice: 0.324515
iteration 340 : loss : 0.277141, loss_ce: 0.086044, loss_dice: 0.324915
iteration 341 : loss : 0.278028, loss_ce: 0.088597, loss_dice: 0.325386
iteration 342 : loss : 0.277537, loss_ce: 0.084454, loss_dice: 0.325807
iteration 343 : loss : 0.274920, loss_ce: 0.069590, loss_dice: 0.326252
iteration 344 : loss : 0.278679, loss_ce: 0.086413, loss_dice: 0.326746
iteration 345 : loss : 0.277934, loss_ce: 0.081769, loss_dice: 0.326976
iteration 346 : loss : 0.284297, loss_ce: 0.117419, loss_dice: 0.326016
iteration 347 : loss : 1.318147, loss_ce: 3.054582, loss_dice: 0.884038
iteration 348 : loss : 0.276592, loss_ce: 0.058650, loss_dice: 0.331077
iteration 349 : loss : 0.294755, loss_ce: 0.138521, loss_dice: 0.333813
iteration 350 : loss : 0.293884, loss_ce: 0.133837, loss_dice: 0.333896
iteration 351 : loss : 0.281178, loss_ce: 0.073054, loss_dice: 0.333209
save model to ./BraTS_output/BraTS_240_pretrain_vit_b_epo3_bs12_lr0.005/epoch_2.pth
 67%|███████████████████████▎           | 2/3 [01:38<00:49, 49.29s/it]
